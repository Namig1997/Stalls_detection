{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.networks import AE, LSTM_predictor\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from random import randint\n",
    "from utils.generators import video2tensor, BatchGenerator\n",
    "import pandas as pd\n",
    "from glob import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "AE = AE(latent_dim=16, size=(64, 64))\n",
    "LSTM_predictor = LSTM_predictor(hidden_size=128)\n",
    "\n",
    "\n",
    "AE_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "LSTM_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "bce = tf.keras.losses.BinaryCrossentropy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(AE, AE_optimizer, LSTM_predictor, LSTM_optimizer, x, label):\n",
    "\n",
    "\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        z = AE.encode(x)\n",
    "        reconstructed_x = AE.decode(z)\n",
    "        features = tf.expand_dims(z, axis=0)\n",
    "        prediction = LSTM_predictor.predict(features)\n",
    "        encoder_loss = bce(x, reconstructed_x)\n",
    "        print(encoder_loss)\n",
    "        predictor_loss = bce(label, prediction)\n",
    "\n",
    "    AE_gradients = tape.gradient(encoder_loss, AE.trainable_variables)\n",
    "    AE_optimizer.apply_gradients(zip(AE_gradients, AE.trainable_variables))\n",
    "    \n",
    "    LSTM_gradients = tape.gradient(predictor_loss, LSTM_predictor.trainable_variables)\n",
    "    LSTM_optimizer.apply_gradients(zip(LSTM_gradients, LSTM_predictor.trainable_variables))\n",
    "    \n",
    "    return encoder_loss, predictor_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "url project_id  \\\nfilename                                                                   \n100000.mp4  s3://drivendata-competition-clog-loss/train/10...          M   \n100001.mp4  s3://drivendata-competition-clog-loss/train/10...          F   \n100002.mp4  s3://drivendata-competition-clog-loss/train/10...          H   \n100003.mp4  s3://drivendata-competition-clog-loss/train/10...          E   \n100004.mp4  s3://drivendata-competition-clog-loss/train/10...          C   \n\n            num_frames  crowd_score  tier1  micro   nano  \nfilename                                                  \n100000.mp4          54     0.000000   True  False  False  \n100001.mp4          48     0.022769  False  False  False  \n100002.mp4         122     0.000000   True  False  False  \n100003.mp4          55     0.000000   True  False  False  \n100004.mp4          56     0.000000   True  False  False  \n"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../res/data/train_metadata.csv\")\n",
    "df.set_index('filename', inplace=True)\n",
    "print(df.head())\n",
    "mp4files = glob(\"../res/data/micro/*.mp4\")\n",
    "#print(df.head())\n",
    "#print(mp4files)\n",
    "labels = [df.loc[f.split(\"/\")[-1], 'crowd_score'] for f in mp4files]\n",
    "labels = [int(round(l)) for l in labels]\n",
    "gen = BatchGenerator(mp4files, labels, size=(64, 64))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'numpy.ndarray'>\n<class 'int'>\ntf.Tensor(1.1448157, shape=(), dtype=float32)\n(<tf.Tensor: id=668, shape=(), dtype=float32, numpy=1.1448157>, <tf.Tensor: id=709, shape=(), dtype=float32, numpy=0.7011006>)\n"
    }
   ],
   "source": [
    "for b in gen:\n",
    "    x = b[0]\n",
    "    print(type(x))\n",
    "    label = b[1]\n",
    "    print(type(label))\n",
    "    enc_loss, pred_loss = train_step(AE, AE_optimizer, LSTM_predictor, LSTM_optimizer, x, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(73, 256, 256, 1)"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "x.shape"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36864bit547641ea7bc0477fbf4007a79b4a8358",
   "display_name": "Python 3.6.8 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}